{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwwoiOhTTt-m",
        "outputId": "58020684-fdf1-4ea1-9009-673fc968bcd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-07-29 15:01:32--  https://font.download/dl/font/card-characters.zip\n",
            "Resolving font.download (font.download)... 104.26.7.36, 104.26.6.36, 172.67.69.242, ...\n",
            "Connecting to font.download (font.download)|104.26.7.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22523 (22K) [application/zip]\n",
            "Saving to: ‘card-characters.zip’\n",
            "\n",
            "\rcard-characters.zip   0%[                    ]       0  --.-KB/s               \rcard-characters.zip 100%[===================>]  22.00K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-07-29 15:01:33 (127 MB/s) - ‘card-characters.zip’ saved [22523/22523]\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  674k  100  674k    0     0   472k      0  0:00:01  0:00:01 --:--:--  472k\n",
            "Archive:  card-characters.zip\n",
            "  inflating: ./CARDC___.TTF          \n",
            "Archive:  font.zip\n",
            "   creating: ./Khepri/\n",
            "  inflating: ./Khepri/Khepri-Textured.otf  \n",
            "  inflating: ./Khepri/Khepri-Round Rough.otf  \n",
            "  inflating: ./Khepri/Khepri.otf     \n",
            "  inflating: ./Khepri/Khepri-Round.otf  \n",
            "  inflating: ./readme.txt            \n"
          ]
        }
      ],
      "source": [
        "# Zoren Martinez 2123873\n",
        "\n",
        "!wget \"https://font.download/dl/font/card-characters.zip\"\n",
        "!curl -L -o font.zip \"https://fontesk.com/download/3484/\"\n",
        "!unzip card-characters.zip -d ./\n",
        "!unzip font.zip -d ./\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCFxmT0aUZf8"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# ======== CONFIGURATION ========\n",
        "main_font_path = 'CARDC___.TTF'\n",
        "ten_font_path = '/content/Khepri/Khepri.otf'\n",
        "\n",
        "characters = ['10', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'J', 'K', 'Q']\n",
        "output_dir = 'dataset'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "font_size = 75\n",
        "size = 128\n",
        "img_size = (size, size)\n",
        "final_binarization_threshold = 180\n",
        "n_samples_per_class = 800\n",
        "\n",
        "# ======== PARAMETERS FOR \"10\" CHARACTER ========\n",
        "ten_stretch_factor = 1.4\n",
        "ten_spacing = 8\n",
        "ten_thickness_factor = 0.55\n",
        "\n",
        "# ======== ROTATION ANGLE LIMITS FOR 'A' ========\n",
        "a_rotation_min = -30\n",
        "a_rotation_max = 0\n",
        "\n",
        "# ======== AUGMENTATION FUNCTION ========\n",
        "def add_augmentations(img, char=None):\n",
        "    np_img = np.array(img).astype(np.uint8)\n",
        "    h, w = np_img.shape\n",
        "\n",
        "    # === Random Scaling ===\n",
        "    scale = random.uniform(1, 1.2)\n",
        "    scaled = cv2.resize(np_img, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    if scale < 1.0:\n",
        "        # Padding\n",
        "        pad_h = (h - scaled.shape[0]) // 2\n",
        "        pad_w = (w - scaled.shape[1]) // 2\n",
        "        np_img = cv2.copyMakeBorder(scaled, pad_h, h - scaled.shape[0] - pad_h,\n",
        "                                    pad_w, w - scaled.shape[1] - pad_w,\n",
        "                                    borderType=cv2.BORDER_CONSTANT, value=255)\n",
        "    else:\n",
        "        # Cropping\n",
        "        start_y = (scaled.shape[0] - h) // 2\n",
        "        start_x = (scaled.shape[1] - w) // 2\n",
        "        np_img = scaled[start_y:start_y + h, start_x:start_x + w]\n",
        "\n",
        "    # === Random Shift ===\n",
        "    max_shift_x = int(w * 0.15)\n",
        "    max_shift_y = int(h * 0.15)\n",
        "    dx = random.randint(-max_shift_x, max_shift_x)\n",
        "    dy = random.randint(-max_shift_y, max_shift_y)\n",
        "    M_shift = np.float32([[1, 0, dx], [0, 1, dy]])\n",
        "    np_img = cv2.warpAffine(np_img, M_shift, (w, h), borderValue=255)\n",
        "\n",
        "    # === Perspective Warp ===\n",
        "    margin = 5\n",
        "    warp_amount = 5\n",
        "    src = np.float32([[margin, margin], [w - margin, margin],\n",
        "                      [margin, h - margin], [w - margin, h - margin]])\n",
        "    dst = src + np.random.uniform(-warp_amount, warp_amount, src.shape).astype(np.float32)\n",
        "    M_persp = cv2.getPerspectiveTransform(src, dst)\n",
        "    np_img = cv2.warpPerspective(np_img, M_persp, (w, h), borderValue=255)\n",
        "\n",
        "    # === Random Rotation ===\n",
        "    if char == 'A':\n",
        "        angle = random.uniform(a_rotation_min, a_rotation_max)\n",
        "    else:\n",
        "        angle = random.uniform(-20, 20)\n",
        "    M_rot = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1)\n",
        "    np_img = cv2.warpAffine(np_img, M_rot, (w, h), borderValue=255)\n",
        "\n",
        "    # === Morphological Closing (clean small holes) ===\n",
        "    closing_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
        "    np_img = cv2.morphologyEx(np_img, cv2.MORPH_CLOSE, closing_kernel)\n",
        "\n",
        "    # === Resize Down and Back Up (simulate blur or pixelation) ===\n",
        "    np_img = cv2.resize(np_img, (56, 56), interpolation=cv2.INTER_AREA)\n",
        "    np_img = cv2.resize(np_img, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    # === Final Binarization ===\n",
        "    _, np_img = cv2.threshold(np_img, final_binarization_threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    return Image.fromarray(np_img)\n",
        "\n",
        "# ======== DATASET GENERATION LOOP ========\n",
        "for char in characters:\n",
        "    char_dir = os.path.join(output_dir, char)\n",
        "    os.makedirs(char_dir, exist_ok=True)\n",
        "\n",
        "    for i in range(n_samples_per_class):\n",
        "        img_base = Image.new('L', img_size, color=255)\n",
        "        draw = ImageDraw.Draw(img_base)\n",
        "\n",
        "        font_size_random = random.randint(int(font_size * 0.85), int(font_size * 1.15))\n",
        "        font = ImageFont.truetype(main_font_path, font_size_random)\n",
        "\n",
        "        if char == '10':\n",
        "            # Special case rendering for '10' using two glyphs: '1' and '0'\n",
        "            font_10 = ImageFont.truetype(ten_font_path, font_size_random)\n",
        "\n",
        "            bbox_1 = draw.textbbox((0, 0), '1', font=font_10)\n",
        "            w1, h1 = bbox_1[2] - bbox_1[0], bbox_1[3] - bbox_1[1]\n",
        "            img_1 = Image.new('L', (w1, h1), color=255)\n",
        "            draw_1 = ImageDraw.Draw(img_1)\n",
        "            draw_1.text((0, 0), '1', font=font_10, fill=0)\n",
        "\n",
        "            bbox_0 = draw.textbbox((0, 0), '0', font=font_10)\n",
        "            w0, h0 = bbox_0[2] - bbox_0[0], bbox_0[3] - bbox_0[1]\n",
        "            img_0 = Image.new('L', (w0, h0), color=255)\n",
        "            draw_0 = ImageDraw.Draw(img_0)\n",
        "            draw_0.text((0, 0), '0', font=font_10, fill=0)\n",
        "\n",
        "            img_1_np = np.array(img_1)\n",
        "            img_0_np = np.array(img_0)\n",
        "            stretched_1 = cv2.resize(img_1_np, (int(w1 * ten_thickness_factor), int(h1 * ten_stretch_factor)), interpolation=cv2.INTER_LINEAR)\n",
        "            stretched_0 = cv2.resize(img_0_np, (int(w0 * ten_thickness_factor), int(h0 * ten_stretch_factor)), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "            combined_width = stretched_1.shape[1] + ten_spacing + stretched_0.shape[1]\n",
        "            combined_height = max(stretched_1.shape[0], stretched_0.shape[0])\n",
        "            combined_img = np.full((combined_height, combined_width), 255, dtype=np.uint8)\n",
        "\n",
        "            offset_y_1 = (combined_height - stretched_1.shape[0]) // 2\n",
        "            offset_y_0 = (combined_height - stretched_0.shape[0]) // 2\n",
        "            combined_img[offset_y_1:offset_y_1 + stretched_1.shape[0], 0:stretched_1.shape[1]] = stretched_1\n",
        "            combined_img[offset_y_0:offset_y_0 + stretched_0.shape[0], stretched_1.shape[1] + ten_spacing:] = stretched_0\n",
        "\n",
        "            scale = min(img_size[0] / combined_width, img_size[1] / combined_height) * 0.65\n",
        "            new_w = int(combined_width * scale)\n",
        "            new_h = int(combined_height * scale)\n",
        "            combined_img = cv2.resize(combined_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "            final_img = np.full(img_size, 255, dtype=np.uint8)\n",
        "            offset_y = (img_size[1] - new_h) // 2\n",
        "            offset_x = (img_size[0] - new_w) // 2\n",
        "            final_img[offset_y:offset_y + new_h, offset_x:offset_x + new_w] = combined_img\n",
        "\n",
        "            img_base = Image.fromarray(final_img)\n",
        "\n",
        "        else:\n",
        "            # Default rendering for all other characters\n",
        "            bbox = draw.textbbox((0, 0), char, font=font)\n",
        "            w_, h_ = bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
        "            ascender, descender = font.getmetrics()\n",
        "            y_offset = (ascender - descender) / 2 * 0.5\n",
        "            pos = ((img_size[0] - w_) / 2, (img_size[1] - h_) / 2 - y_offset)\n",
        "            draw.text(pos, char, fill=0, font=font)\n",
        "\n",
        "        img_aug = add_augmentations(img_base, char=char)\n",
        "        img_aug.save(os.path.join(char_dir, f'{char}_{i}.png'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHUAq25Ydh_W",
        "outputId": "ce2f4bbf-665e-4c82-bd8a-ed3ce13b4522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10] Loss: 0.7062, Accuracy: 76.63%\n",
            "Epoch [2/10] Loss: 0.0525, Accuracy: 98.53%\n",
            "Epoch [3/10] Loss: 0.0294, Accuracy: 99.15%\n",
            "Epoch [4/10] Loss: 0.0126, Accuracy: 99.64%\n",
            "Epoch [5/10] Loss: 0.0111, Accuracy: 99.66%\n",
            "Epoch [6/10] Loss: 0.0203, Accuracy: 99.38%\n",
            "Epoch [7/10] Loss: 0.0145, Accuracy: 99.64%\n",
            "Epoch [8/10] Loss: 0.0061, Accuracy: 99.79%\n",
            "Epoch [9/10] Loss: 0.0110, Accuracy: 99.65%\n",
            "Epoch [10/10] Loss: 0.0189, Accuracy: 99.50%\n",
            "Training completed. Weights saved.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "dataset_dir = 'dataset'\n",
        "\n",
        "# Image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=dataset_dir, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "num_classes = len(train_dataset.classes)\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # Output: 32x128x128\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                             # Output: 32x64x64\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # Output: 64x64x64\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                             # Output: 64x32x32\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),# Output: 128x32x32\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                             # Output: 128x16x16\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),                                # Output: 128x16x16\n",
        "            nn.Linear(128 * 16 * 16, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN(num_classes=num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "torch.save(model.state_dict(), 'simple_card_classifier_weights.pth')\n",
        "print(\"Training completed. Weights saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rk8K2ds3dmOj"
      },
      "outputs": [],
      "source": [
        "model = SimpleCNN(num_classes=13)\n",
        "model.load_state_dict(torch.load('simple_card_classifier_weights.pth', map_location='cpu'))\n",
        "model.eval()\n",
        "\n",
        "example_input = torch.randn(1, 1, size, size)\n",
        "\n",
        "traced_model = torch.jit.trace(model, example_input)\n",
        "\n",
        "traced_model.save(\"simple_card_classifier_traced.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "u1MUHbKxdpUV",
        "outputId": "6c97508c-fa61-4c8e-bec8-c4eb3d4b2598"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_fc575b50-4043-4b92-8e56-2cfc3236521f\", \"simple_card_classifier_traced.pt\", 33972217)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/simple_card_classifier_traced.pt')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
